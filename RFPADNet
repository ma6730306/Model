from __future__ import print_function
from keras.layers import (Input, Dense, Conv2D, Activation, BatchNormalization,
                          MaxPooling2D, UpSampling2D, AveragePooling2D, Add, Multiply, concatenate,
                          GlobalAveragePooling2D, Dropout)
from keras.models import Model

def FPAmodule(x,nb_filter,name):

    x1_1 = AveragePooling2D(pool_size=(2, 2), strides=2, padding='same', name =name + '1_down')(x)
    x1_2 = Conv2D(nb_filter, (1, 1), padding='same', strides=1, name =name + '1_cov')(x1_1)
    x1_3 = BatchNormalization(axis=3, epsilon=1.0001e-5, name=name + '1_bn')(x1_2)
    x1_4 = Activation('relu')(x1_3)
    x1_5 = UpSampling2D(size=(2, 2))(x1_4)


    x2_1 = Conv2D(nb_filter, (1, 1), padding='same', strides=1, name=name + 'middle_cov')(x)
    x2_2 = BatchNormalization(axis=3, epsilon=1.0001e-5, name=name + 'middle_bn')(x2_1)
    x2_3 = Activation('relu')(x2_2)


    x3_1d = MaxPooling2D(pool_size=2, strides=2, padding='same', name =name + '3_down')(x)
    x3_1 = Conv2D(nb_filter, (7, 7), padding='same', strides=1, name=name + '3_cov1')(x3_1d)
    x3_2 = BatchNormalization(axis=3, epsilon=1.0001e-5, name=name + '3_bn1')(x3_1)
    x3_3 = Activation('relu')(x3_2)

    x3_4 = Conv2D(nb_filter, (3, 3), padding='same', strides=1, name=name + '3_cov2')(x3_3)
    x3_5 = BatchNormalization(axis=3, epsilon=1.0001e-5, name=name + '3_bn2')(x3_4)
    x3_6 = Activation('relu')(x3_5)

    x3_7 = Conv2D(nb_filter, (3, 3), padding='same', strides=1, name=name + '3_cov3')(x3_6 )
    x3_8 = BatchNormalization(axis=3, epsilon=1.0001e-5, name=name + '3_bn3')(x3_7)
    x3_9 = Activation('relu')(x3_8)

    x3_10 = Conv2D(nb_filter, (3, 3), padding='same', strides=1, name=name + '3_cov4')(x3_9)
    x3_11 = BatchNormalization(axis=3, epsilon=1.0001e-5, name=name + '3_b4')(x3_10)
    x3_12 = Activation('relu')(x3_11)


    x4_1d = MaxPooling2D(pool_size=2, strides=2, padding='same', name =name + '4_down')(x3_3)
    x4_1 = Conv2D(nb_filter, (5, 5), padding='same', strides=1, name=name + '4_cov1')(x4_1d)
    x4_2 = BatchNormalization(axis=3, epsilon=1.0001e-5, name=name + '4_bn1')(x4_1)
    x4_3 = Activation('relu')(x4_2)

    x4_4 = Conv2D(nb_filter, (3, 3), padding='same', strides=1, name=name + '4_cov2')(x4_3)
    x4_5 = BatchNormalization(axis=3, epsilon=1.0001e-5, name=name + '4_bn2')(x4_4)
    x4_6 = Activation('relu')(x4_5)

    x4_7 = Conv2D(nb_filter, (3, 3), padding='same', strides=1, name=name + '4_cov3')(x4_6)
    x4_8 = BatchNormalization(axis=3, epsilon=1.0001e-5, name=name + '4_bn3')(x4_7)
    x4_9 = Activation('relu')(x4_8)


    x5_1d = MaxPooling2D(pool_size=2, strides=2, padding='same', name=name + '5_down')(x4_3)
    x5_1 = Conv2D(nb_filter, (3, 3), padding='same', strides=1, name=name + '5_cov1')(x5_1d)
    x5_2 = BatchNormalization(axis=3, epsilon=1.0001e-5, name=name + '5_bn')(x5_1)
    x5_3 = Activation('relu')(x5_2)

    x5_4 = Conv2D(nb_filter, (3, 3), padding='same', strides=1, name=name + '5_cov2')(x5_3)
    x5_5 = BatchNormalization(axis=3, epsilon=1.0001e-5, name=name + '5_bn1')(x5_4)
    x5_6 = Activation('relu')(x5_5)

    x5 = UpSampling2D(size=(2, 2))(x5_6)
    x6 = Add()([x5, x4_9])

    x7 = UpSampling2D(size=(2, 2))(x6)
    x8 = Add()([x7,  x3_12])

    x9 = UpSampling2D(size=(2, 2))(x8)
    x10 = Multiply()([x9, x2_3])
    x = Add()([x10, x1_5])

    return x

def RFPAmodule(x, nb_filter,name):

    xr1 = MaxPooling2D(pool_size=(2, 2), strides=2, padding='same')(x)
    xr2 = UpSampling2D(size=(2, 2))(xr1)
    xr3 = Conv2D(nb_filter, kernel_size=(1, 1), strides=1, padding='same')(xr2)
    xr4 = Activation('sigmoid')(xr3)
    xm = FPAmodule(x, nb_filter, name)
    x1 = Multiply()([xr4, xm])
    x2 = Conv2D(filters=nb_filter, kernel_size=(1, 1), strides=1, padding='same')(x)
    x = Add()([x2, x1])

    return x

def DenseLayer(x, nb_filter, name, drop_rate, bn_size=2):

    x1 = BatchNormalization(axis=3, epsilon=1.0001e-5, name=name + '2_0_bn')(x)
    x1 = Activation('relu')(x1)
    x1 = Conv2D(bn_size * nb_filter, (1, 1), strides=(1, 1), padding='same',  name=name + '2_1_conv')(x1)

    x1 = RFPAmodule(x1, nb_filter, name)

    if drop_rate:
        x1 = Dropout(drop_rate)(x1)
    x = concatenate([x, x1], axis=3, name=name + '2_concat')

    return x

def DenseBlock(x, layers, growth_rate, name, drop_rate):
    for i in range(layers):
        x = DenseLayer(x, nb_filter=growth_rate, drop_rate=drop_rate, name=name + '2_block' + str(i + 1))
    return x

def TransitionLayer(x, name, compression=0.5):

    nb_filter = int(x.shape.as_list()[-1] * compression)
    x = BatchNormalization(axis=3, epsilon=1.0001e-5, name=name + '_bn')(x)
    x = Activation('relu')(x)
    x = Conv2D(nb_filter, (1, 1), strides=(1, 1), padding='same', name=name + '_conv')(x)

    x = AveragePooling2D(pool_size=(2, 2), strides=2, name=name + 'a_conv')(x)

    return x

def RFPADNet():

    input_shape = [256, 256, 3]
    img_input = Input(shape=input_shape)
    growth_rate = 32

    x = Conv2D(2*growth_rate, (3, 3), strides=1, padding='same', name='conv1/conv')(img_input)
    x = BatchNormalization(axis=3, name='conv1/bn')(x)
    x = Activation('relu')(x)
    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(x)

    x = DenseBlock(x, 4, growth_rate, drop_rate=0.2, name='conv1')

    x = TransitionLayer(x, name='pool1')

    x = DenseBlock(x, 4, growth_rate, drop_rate=0.2, name='conv2')

    x = TransitionLayer(x, name='pool2')

    x = DenseBlock(x, 4, growth_rate, drop_rate=0.2, name='conv3')

    x = BatchNormalization(axis=3, epsilon=1.0001e-5, name='bn')(x)

    x = GlobalAveragePooling2D(name='avg_pool')(x)

    x = Dense(2, activation='softmax', name='fc2')(x)

    model = Model(img_input, x, name='RFPADNet')

    return model
